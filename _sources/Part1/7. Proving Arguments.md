# Proving Arguments

## Proof by Truth Table
Consider the following, familiar, argument:

> If it is raining I take an umbrella
> It is raining
> Therefore, I take an umbrella

Using an obvious notation, we can express this as

> $R\implies U$, $R$, $\therefore U$

This is obvious, but can we prove it beyond ay residual doubt. One very obvious way to do this is to construct the truth table:

| $R$ | $U$ | $R\implies U$ |
|:---:|:---:|:-------------:|
|  F  |  F  |  T            |
|  F  |  T  |  T            |
|  T  |  F  |  F            |
|  T  |  T  |  T            |

*In which row of this table are the two premises ($R\implies U$, $R$) True? Is $U$ True or False on that row?*

We can construct a truth table for any argument and use the truth table to prove its correctness. This is extremely rigourous and is also very easy to automate. What it is not, however, is practical for anything but small problems: an argument involving $N$ atomic premises has $2^N$ rows in its truth table. This very quickly becomes extremely slow to compute and very memory intensive for even modestly sized systems.

We will therefore explore a different proof technique known as **natural deduction**. This approach is much more similar to what we would recognise as a "mathematical proof" and is much more easily transferrable to other forms of logic such as **first order logic** which we will soon move on to study. It is also more suitable for studying systems with many propositions as we do not need to enumerate all of of the models explicitly.

## Natural Deduction

Natural deduction involves application of so-called **inference rules** to the premises of an argument. The rules manipulate the premises in ways that are provably correct to create new statements. If the premises are True, and the rules have been applied correctly, then the consequents must also be True. We use the inference rules to perform substitions into the premises until we have arrived at the conclusion (or contradicted it). Here's an example of how we do this. Consider the following argument (using symbols previously defined for **R**aining, **O**utdoors, **C**oat):

> $\lnot(R\land O)\implies\lnot C$  
> $C$  
> $O$  
> $\therefore R$

(What is this argument in "English"? Does it makes sense?)

We can prove this argument via the following set of steps:

> $\lnot(R\land O)\implies\lnot C,\ C,\ O\ :\ R$  
>
> | Step |                                    | Rule | Premises |
> |-----:|:-----------------------------------|:-----|-------------:|
> | 1.   | $\lnot(R\land O)\implies\lnot C$   | Premise | {1}|
> | 2.   | $C$                                | Premise | {2}|
> | 3.   | $O$                                | Premise | {3}|
> | 4.   | $\lnot\lnot (R\land O)$            | Modus tollens $_{1,2}$ | {1,2}|
> | 5.   | $R\land O$                         | Double negation elimination $_4$ | {1,2} |
> | 6.   | $R$                                | $\land$-elimination $_5$ | {1,2,3}|

We have proven the argument. Let us observe some features of the proof

- Each line of the proof consists of a single proposition.
- A proposition is either a premise or results from an application of exactly one rule of inference to one or more other propositions. 
- When a rule of inference is applied, the propositions to which it has been applied should be stated as a subscript. For example, the application of Modus Tollens in line 4 uses propositions 1 and 2, whilst the double negation in line 5 uses proposition 4.
- The *premises* on which a proposition depends should be listed in the final column, regardless of whether they have been used directly in the application of a rule. For examples, line 5 does not use premises 1 and 2 directly, but they were used to derive premise 4, which the rule does use directly.

In sequent form, we write

> $\lnot(R\land O)\implies\lnot C,\ C,\ O\ \vdash R$

Notice that this is subtly different to the outcome of a truth table-based argument, by the use of $\vdash$ instead of $\vDash$. This denotes that the argument has been shown to be **syntactically correct** by virtue of having been derived using a set of logical inference rules that have themselves been verified as sematically correct. The overall argument itself has not been explicitly shown to be *sematically correct* which is what a truth table does and this form of proof is sometimes regarded as weaker than more explicit semantic proofs. It is, nevertheless, widely accepted as a valid form of proof.

This proof of $R$ by **natural deduction** that uses only the premises of the argument and some established valid rules of inference. Examples of common inference rules include

> | Rule                         | Description  |
> |:----------------------------:|:------------:|
> | $P\implies Q$, $P\vDash Q$ | Modus Ponens |
> | $P\implies Q$, $\lnot Q\vDash \lnot P$ | Modus Tollens |
> | $\lnot\lnot P \vDash P$ | Elimination of double negation |
> | $P,Q\vDash P\land Q$ | $\land$-introduction |
> | $P,P\land Q\vDash P$ | $\land$-elimination |
> | $P\vDash P\lor Q$ | $\lor$-introduction |
> | $\lnot (P\lor Q) \vDash \lnot P$. | Modus Tollendo Ponens |
> | $P\iff Q \vDash P\implies Q$ or $Q\implies P$ | Biconditional elimination |

Each of these inference rules can be sematically validated via a truth table and syntactically applied via symbolic manipulation during a proof.

Let's do another, more complex example. This time, we will consider an *abstract* problem so we can focus on the symbolic manipulations.

> $P\implies Q\land R,\ \lnot R,\ P\iff S,\ : \lnot S$
>
> | Step |                        | Rule | Premises |
> |-----:|:-----------------------|:-----|-------------:|
> | 1.   | $P\implies Q\land R$   | Premise | {1} |
> | 2.   | $\lnot R$              | Premise | {2} |
> | 3.   | $\lnot(Q\land R)$      | $\land$-introduction $_2$ | {2} |
> | 4.   | $\lnot P$              | Modus Tollens $_{1,3}$    | {1,2} |
> | 5.   | $P\iff S$              | Premise | {5} |
> | 6.   | $S\implies P$          | Biconditional-elimination $_{5}$ | {5} |
> | 7.   | $\lnot S$              | Modus Tollens $_{5,6}$ | {1,2,5} |

We can therefore write
> $P\implies Q\land R,\ \lnot R,\ P\iff S,\ \vdash \lnot S$

Notice how, at stage 3, we have used $\land$-introduction by noticing that if $R$ is False, then $Q\land R$ must also be False irrespective of $Q$.

Proofs can also be used to show that arguments are *invalid*. Two ways to do this are:

> 1. By showing the the *negation* of the conclusion is true. For example, if the argument concludes $Q$ but you are able to show that $\lnot Q$, then the argument must be invalid.
> 2. By deriving a *contradiction*. If an argument concludes $Q$ and you are able to prove that $Q$ and $\lnot Q$, then the argument must be invalid.
