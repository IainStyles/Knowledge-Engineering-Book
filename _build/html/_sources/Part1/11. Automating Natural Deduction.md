# Automating Natural Deduction

Natural Deduction is very similar in principle and practice to mathematical proof: to show that some statement is true, we take some statements that we know to be true and perform a series of well-defined symbol manipulations until we are able to produce the statement that we wish to prove. This is all quite straightforward when we have a small number of statements to work with, but this soon becomes very challenging with large numbers of statements, because of the combinatorial possibilities. In any case, performing the derivations needed to prove new statements can become rather tedious once one has learned how to do it. It is natural to want to automate this.

The rules of natural deduction are not easy to apply mechanistically. As humans, we use our intuition to figure out what rules to apply, and in what order. The computer has no such in-built intuition, and we have not yet understood how to properly program computers to emulate our human intuition. We could, of course, simply systematically and sequentially apply all possible rules until we arrive at the target statement that we want to prove, but with many possible rules and the potential for large knowledge bases, this become impractical very quickly.

An automated approach to natural deduction would be much simpler to implement if there was some uniformity in the statements that make up the knowledge base. Fortunately, the rules of logic make it possible for us to do this relatively easily. Consider the logical statements $P\implies Q$, $P\land Q$, and $P\lor Q$. We have seen how to manipulate these statements in a proof (noting that `or` is not at all straightforward to work with). If we could represent our knowledge using only one of these operators, natural deduction would be far more straightforward. Fortunately, this turns out to be quite a simple thing to do. Consider the truth tables for these operators:

| $P$ | $Q$ | $P\land Q$ | $P\lor Q$ | $P\implies Q$ |
|:---:|:---:|:----------:|:---------:|:-------------:|
| F   | F   | F          | F         | T             |
| F   | T   | F          | T         | T             |
| T   | F   | F          | T         | F             |
| T   | T   | T          | T         | T             |

It is very easy to verify from the truth table that the following relationship between these operators hold (allowing the use of `not` as well):

$$P\land Q \equiv \lnot(P\implies\lnot Q)\quad \leftrightarrow\quad P\implies Q \equiv \lnot(P\land\lnot Q)$$

$$P\lor Q \equiv \lnot P\implies Q \quad \leftrightarrow\quad P\implies Q \equiv \lnot P\lor Q$$

These relations allow us to rewrite any knowledge base in terms of **material implication** and `not`. This representation of a knowledge base is sometimes called a **rule-based system** and it permits a very powerful approach to inference in which we need just one inference rules: *modus ponens*.

We will study two ways to draw inferences from such a system. In the first, we will start with the rules of the knowledge base and combine them in different ways until we reach the statement that we are trying to prove (the goal). In the second, we start with the goal, and work backwards to see if it is compatible with the known facts. Both approaches rely on being able to systematically *search* the knowledge base to find those facts that are compatible with the goal.

## Forward Chaining

Consider a Knowledge Base expressed in terms of material implications. Given a few initial facts, we want be able to determine new information from the knowledge base. Consider this very simple example:

1. If $x$ eats grass and goes "moo" then $x$ is a cow.
2. If $x$ eats hay and goes "neigh" then $x$ is a horse.
3. If $x$ eats grass and goes "baa" then $x$ is a sheep.
4. If $x$ is a cow then $x$ is brown.
5. If $x$ is a horse then $x$ is black.
6. If $x$ is a sheep then $x$ is white.

Let us now assume that we know two facts ablout a particular animal - let's call them "Jeff":

- Jeff eats hay
- Jeff goes "neigh".

Can we use our rule base to derive what colour Jeff is? Yes we can, by repeated application of *modus ponens*.

* We first check to see if we can find a rule for which, given our two facts, the antecedent is True. We find that it is so for rule 2: "If Jeff eats hay and goes 'neigh' then Jeff is a horse."
* By modus ponens, we can now take the consequent of rule 2 to be true ("Jeff is a horse") and look again at the rules to see if any of the antecedents are true. We find that this is the case for rule 5.
* By modus ponens on rule 5, we find that Jeff is black.

This styles of inference - sequential application of modus ponens - is known as **forward chaining**.

## Backward Chaining

Backward chaining starts with a goal statement, and aims to determine whether the goal is consistent with the knowledge base. 

Let us imagine that we know two facts about another animal called "Jess":

- Jess eats grass
- Jess goes "baa"

This time, let us imagine we have a hypothesis that we want to test: "Jess is white". This is our "goal" statement.

* We check all of the consequents to see if any of them match the goal. Rule 6 matches. Now of course, the consequent of an implication can be true when the antecedent is false, so this does not automatically mean that Jess is a sheep, so we have to create a new goal: "Jess is a sheep".
* Matching our new goal against the consequents of our rules, we find that rule 3 matches. Our new goal is therefore to prove that "Jess eats grass and goes 'baa'", which is equivalent to two subgoals, "Jess eats grass" and "Jess goes 'baa'".
* Both subgoals were stated as initial facts. We can therefore take the antecedent of Rule 3 to be True, and so the consequent ("Jess is a sheep") must also be True by modus ponens.
* We can propagate this through rule 6 via modus ponens to prove that "Jess is white".



## A Comparison of Forward vs Backward Chaining

Forward and backward chaining have different use-cases. Forward chaining starts with the facts and uses them to derive new facts. This process can happen dynamically, and so if we learn something new and add it to the knowledge based, we can use forward chaining to derive new facts without any particular goal in mind. For example, given our rules

1. If $x$ eats grass and goes "moo" then $x$ is a cow;
2. If $x$ eats hay and goes "neigh" then $x$ is a horse;
3. If $x$ eats grass and goes "baa" then $x$ is a sheep;
4. If $x$ is a cow then $x$ is brown;
5. If $x$ is a horse then $x$ is black;
6. If $x$ is a sheep then $x$ is white;

we can derive the following new rules

1. If $x$ eats grass and goes "moo" then $x$ is brown [rules 1+4];
2. If $x$ eats hay and goes "neigh" then $x$ is a horse [rules 2+5];
3. If $x$ eats grass and goes "baa" then $x$ is a sheep [rule 3+6].

These can then be added to the knowledge base, which can then grow dynamically as new facts are added. Thus, forward chaining can be used without necessarily having a specific goal/question in mind, and we can use it to answer question such as "what colour is Jeff?".

If we have a specific hypothesis that we wish to test ("Jess is white?") then we can of course answer this using forward chaining, but one drawback of this is that since forward chaining starts with the known facts and tests the antecedents of our rules, we do not know whether the desired goal is a possible consequent of any of the rules. Consider what would happen if we made our goal the hypothesis "Jess is Red". We would have to follow all possible forward paths through the rule base to determine that there was no consequent that would confirm the hypothesis. With backward chaining, which is said to be *goal-driven*, we test the consequents first, so if "$x$ is Red" is not found in the set of possible consequents we know that we can immediately reject the hypothesis. Backward chaining also invokes only those rules that can lead to the desired consequent and thus can be much more efficient. With forward chaining, it is possible to head down dead-end pathways. Forwards and Backward Chaining are therefore employed with different tasks in mind (typically open vs closed questions). 